{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Mean Embedding (KME) Classification\n",
    "\n",
    "Treat the **decoded field** as a distribution over (position, value). Embed each image's field into an RKHS via a product kernel (spatial × value), then use **kernel SVM** on the Gram matrix.\n",
    "\n",
    "- **Field:** Query decoder at grid points → (x_i, y_i, z_i) with z_i = decoded RGB.\n",
    "- **Kernel:** k((x,y,z), (x',y',z')) = k_space((x,y),(x',y')) × k_val(z,z'); both RBF.\n",
    "- **K(I, I')** = ⟨μ[I], μ[I']⟩ = (1/n²) ∑_{i,j} k(p_i, p'_j).\n",
    "- **Classification:** sklearn SVM with precomputed kernel (Gram matrix)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from einops import repeat\n",
    "\n",
    "from nf_feature_models import (\n",
    "    CascadedPerceiverIO,\n",
    "    GaussianFourierFeatures,\n",
    "    create_coordinate_grid,\n",
    "    prepare_model_input,\n",
    ")\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "CHECKPOINT_DIR = \"checkpoints\"\n",
    "CKPT_PATH = os.path.join(CHECKPOINT_DIR, \"checkpoint_best.pt\")\n",
    "if not os.path.isfile(CKPT_PATH):\n",
    "    CKPT_PATH = os.path.join(CHECKPOINT_DIR, \"checkpoint_last.pt\")\n",
    "assert os.path.isfile(CKPT_PATH), f\"No checkpoint in {CHECKPOINT_DIR}. Train AblationCIFAR10 first.\"\n",
    "\n",
    "IMAGE_SIZE = 32\n",
    "CHANNELS = 3\n",
    "FOURIER_MAPPING_SIZE = 96\n",
    "POS_EMBED_DIM = FOURIER_MAPPING_SIZE * 2\n",
    "INPUT_DIM = CHANNELS + POS_EMBED_DIM\n",
    "QUERIES_DIM = POS_EMBED_DIM\n",
    "LOGITS_DIM = CHANNELS\n",
    "\n",
    "fourier_encoder = GaussianFourierFeatures(2, FOURIER_MAPPING_SIZE, scale=15.0).to(DEVICE)\n",
    "model = CascadedPerceiverIO(\n",
    "    input_dim=INPUT_DIM,\n",
    "    queries_dim=QUERIES_DIM,\n",
    "    logits_dim=LOGITS_DIM,\n",
    "    latent_dims=(256, 384, 512),\n",
    "    num_latents=(256, 256, 256),\n",
    "    decoder_ff=True,\n",
    ").to(DEVICE)\n",
    "ckpt = torch.load(CKPT_PATH, map_location=DEVICE)\n",
    "model.load_state_dict(ckpt[\"model_state_dict\"], strict=False)\n",
    "fourier_encoder.load_state_dict(ckpt[\"fourier_encoder_state_dict\"], strict=False)\n",
    "model.eval()\n",
    "fourier_encoder.eval()\n",
    "\n",
    "coords_32 = create_coordinate_grid(IMAGE_SIZE, IMAGE_SIZE, DEVICE)\n",
    "print(f\"Loaded {CKPT_PATH}\")\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_residual(model, data):\n",
    "    residual = None\n",
    "    for block in model.encoder_blocks:\n",
    "        residual = block(x=residual, context=data, mask=None, residual=residual)\n",
    "    for sa_block in model.self_attn_blocks:\n",
    "        residual = sa_block[0](residual) + residual\n",
    "        residual = sa_block[1](residual) + residual\n",
    "    return residual\n",
    "\n",
    "\n",
    "def decoder_forward(model, queries, context):\n",
    "    x = model.decoder_cross_attn(queries, context=context)\n",
    "    x = x + queries\n",
    "    if model.decoder_ff is not None:\n",
    "        x = x + model.decoder_ff(x)\n",
    "    return model.to_logits(x)\n",
    "\n",
    "\n",
    "def get_field_points(model, fourier_encoder, data, coords, device, point_indices=None):\n",
    "    \"\"\"\n",
    "    Query the field (one decode with full latent) to get (x,y,z) at grid points.\n",
    "    data: (B, N, input_dim), coords: (N, 2).\n",
    "    Returns: (B, n_pts, 5) with last dim = (x, y, z_r, z_g, z_b); if point_indices given, n_pts = len(point_indices).\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        residual = get_residual(model, data)\n",
    "        B = data.size(0)\n",
    "        N = coords.size(0)\n",
    "        if point_indices is not None:\n",
    "            coords_sub = coords[point_indices]\n",
    "            n_pts = len(point_indices)\n",
    "        else:\n",
    "            coords_sub = coords\n",
    "            n_pts = N\n",
    "        queries = fourier_encoder(repeat(coords_sub, \"n d -> b n d\", b=B)).to(device)\n",
    "        z = decoder_forward(model, queries, residual)\n",
    "        z = z.cpu().numpy()\n",
    "        xy = coords_sub.cpu().numpy()\n",
    "    points = np.zeros((B, n_pts, 5), dtype=np.float32)\n",
    "    points[:, :, :2] = xy[None, :, :]\n",
    "    points[:, :, 2:5] = z\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel_2d(X, Y, sigma):\n",
    "    \"\"\"X (n,2), Y (m,2) -> (n,m) RBF k(x,y) = exp(-||x-y||^2 / (2*sigma^2)).\"\"\"\n",
    "    X = np.asarray(X, dtype=np.float64)\n",
    "    Y = np.asarray(Y, dtype=np.float64)\n",
    "    sq_dists = np.sum(X**2, axis=1, keepdims=True) + np.sum(Y**2, axis=1) - 2 * (X @ Y.T)\n",
    "    return np.exp(-np.maximum(sq_dists, 0) / (2 * sigma**2))\n",
    "\n",
    "\n",
    "def rbf_kernel_val(Z, W, sigma):\n",
    "    \"\"\"Z (n,d), W (m,d) -> (n,m) RBF in value space.\"\"\"\n",
    "    Z = np.asarray(Z, dtype=np.float64)\n",
    "    W = np.asarray(W, dtype=np.float64)\n",
    "    sq_dists = np.sum(Z**2, axis=1, keepdims=True) + np.sum(W**2, axis=1) - 2 * (Z @ W.T)\n",
    "    return np.exp(-np.maximum(sq_dists, 0) / (2 * sigma**2))\n",
    "\n",
    "\n",
    "def product_kernel_gram_two(P, Q, sigma_space, sigma_val):\n",
    "    \"\"\"\n",
    "    P (n, 5): (x,y,z1,z2,z3) for image I.\n",
    "    Q (m, 5): for image I'.\n",
    "    Returns K(I,I') = (1/(n*m)) sum_{i,j} k_space(p_i,q_j) * k_val(p_i,q_j).\n",
    "    \"\"\"\n",
    "    n, m = P.shape[0], Q.shape[0]\n",
    "    k_s = rbf_kernel_2d(P[:, :2], Q[:, :2], sigma_space)\n",
    "    k_v = rbf_kernel_val(P[:, 2:5], Q[:, 2:5], sigma_val)\n",
    "    return np.sum(k_s * k_v) / (n * m)\n",
    "\n",
    "\n",
    "def gram_matrix(points_list, sigma_space, sigma_val):\n",
    "    \"\"\"points_list: list of (n_i, 5) arrays. Returns Gram (N, N). Vectorized inner loop.\"\"\"\n",
    "    N = len(points_list)\n",
    "    Gram = np.zeros((N, N), dtype=np.float64)\n",
    "    for i in range(N):\n",
    "        for j in range(i, N):\n",
    "            Gram[i, j] = Gram[j, i] = product_kernel_gram_two(\n",
    "                points_list[i], points_list[j], sigma_space, sigma_val\n",
    "            )\n",
    "    return Gram\n",
    "\n",
    "\n",
    "def gram_test_train(test_points_list, train_points_list, sigma_space, sigma_val):\n",
    "    \"\"\"K(test_i, train_j) -> (n_test, n_train).\"\"\"\n",
    "    n_test = len(test_points_list)\n",
    "    n_train = len(train_points_list)\n",
    "    K = np.zeros((n_test, n_train), dtype=np.float64)\n",
    "    for i in range(n_test):\n",
    "        for j in range(n_train):\n",
    "            K[i, j] = product_kernel_gram_two(\n",
    "                test_points_list[i], train_points_list[j], sigma_space, sigma_val\n",
    "            )\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Subsample for tractability (Gram is O(N^2 * n^2)); increase if you have time\n",
    "N_TRAIN_KME = 1500\n",
    "N_TEST_KME = 500\n",
    "N_POINTS = 128  # points per image (subsample 32*32 grid)\n",
    "\n",
    "np.random.seed(42)\n",
    "train_idx = np.random.choice(len(train_dataset), size=N_TRAIN_KME, replace=False)\n",
    "test_idx = np.random.choice(len(test_dataset), size=N_TEST_KME, replace=False)\n",
    "point_indices = np.random.choice(IMAGE_SIZE * IMAGE_SIZE, size=N_POINTS, replace=False)\n",
    "\n",
    "train_sub = Subset(train_dataset, train_idx)\n",
    "test_sub = Subset(test_dataset, test_idx)\n",
    "train_loader = DataLoader(train_sub, batch_size=32, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_sub, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"N_train={N_TRAIN_KME}, N_test={N_TEST_KME}, n_points={N_POINTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_points_from_loader(loader, model, fourier_encoder, coords_32, device, point_indices):\n",
    "    all_points = []\n",
    "    for images, _ in loader:\n",
    "        images = images.to(device)\n",
    "        input_data, _, _ = prepare_model_input(images, coords_32, fourier_encoder)\n",
    "        pts = get_field_points(model, fourier_encoder, input_data, coords_32, device, point_indices)\n",
    "        for b in range(pts.shape[0]):\n",
    "            all_points.append(pts[b])\n",
    "    return all_points\n",
    "\n",
    "\n",
    "print(\"Extracting field points for training...\")\n",
    "train_points_list = extract_points_from_loader(\n",
    "    train_loader, model, fourier_encoder, coords_32, DEVICE, point_indices\n",
    ")\n",
    "train_labels = np.array([train_dataset[i][1] for i in train_idx])\n",
    "print(f\"Train: {len(train_points_list)} samples, each {train_points_list[0].shape}\")\n",
    "\n",
    "print(\"Extracting field points for test...\")\n",
    "test_points_list = extract_points_from_loader(\n",
    "    test_loader, model, fourier_encoder, coords_32, DEVICE, point_indices\n",
    ")\n",
    "test_labels = np.array([test_dataset[i][1] for i in test_idx])\n",
    "print(f\"Test: {len(test_points_list)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIGMA_SPACE = 0.5\n",
    "SIGMA_VAL = 1.0\n",
    "\n",
    "print(\"Computing Gram matrix (train x train)...\")\n",
    "Gram_train = gram_matrix(train_points_list, SIGMA_SPACE, SIGMA_VAL)\n",
    "print(f\"Gram_train shape: {Gram_train.shape}\")\n",
    "\n",
    "print(\"Computing kernel matrix test x train...\")\n",
    "K_test_train = gram_test_train(test_points_list, train_points_list, SIGMA_SPACE, SIGMA_VAL)\n",
    "print(f\"K_test_train shape: {K_test_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "print(\"Training kernel SVM (precomputed kernel)...\")\n",
    "clf = SVC(kernel=\"precomputed\", C=1.0, class_weight=\"balanced\")\n",
    "clf.fit(Gram_train, train_labels)\n",
    "\n",
    "pred_test = clf.predict(K_test_train)\n",
    "acc = np.mean(pred_test == test_labels)\n",
    "print(f\"Test accuracy (KME + kernel SVM): {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
